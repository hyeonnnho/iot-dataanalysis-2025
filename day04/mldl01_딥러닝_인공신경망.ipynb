{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222582a2",
   "metadata": {},
   "source": [
    "## 딥러닝\n",
    "\n",
    "### 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003dfe5b",
   "metadata": {},
   "source": [
    "#### Tensorflow\n",
    "- https://www.tensorflow.org/?hl=ko\n",
    "- 딥러닝 라이브러리 중 가장 유명\n",
    "- 구글 브레인팀에서 개발\n",
    "\n",
    "#### PyTorch\n",
    "- https://pytorch.org/\n",
    "- https://pytorch.kr/\n",
    "- 메타(페이스북)에서 개발한 딥러닝 라이브러리\n",
    "- GPU 사용이 매우 용이해서 빨리 처리가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6d296",
   "metadata": {},
   "source": [
    "#### MNIST 데이터\n",
    "- AI에서 많이 사용하는 데이터셋 중 하나\n",
    "- 미국 국립표준기술연구소에서 배포하는 이미지 데이터\n",
    "- 손글씨(0~9), 붓꽃데이터, 패션데이터, Cifar10(컬러 이미지)등 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df23466",
   "metadata": {},
   "source": [
    "Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da405852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 사용\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aa3903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 패션MNIST를 로드하면서 훈련 세트와 테스트 세트로 분리\n",
    "# sklearn train_test_split()와 변수 배치가 다름!\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffadf5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개 이미지 데이터, 넓이 28픽셀, 높이 28픽셀\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d975aa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개 이미지에 대한 분류값\n",
    "train_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75658fc",
   "metadata": {},
   "source": [
    "#### 이미지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698a4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891485c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hyeonho/Documents/GitHub/iot-dataanalysis-2025/day04/C:/Windows/Fonts/malgun.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rcParams, font_manager, rc\n\u001b[32m      4\u001b[39m font_path = \u001b[33m'\u001b[39m\u001b[33mC:/Windows/Fonts/malgun.ttf\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m font = \u001b[43mfont_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFontProperties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m rc(\u001b[33m'\u001b[39m\u001b[33mfont\u001b[39m\u001b[33m'\u001b[39m, family=font)\n\u001b[32m      7\u001b[39m rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.unicode_minus\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/matplotlib/font_manager.py:731\u001b[39m, in \u001b[36mFontProperties.get_name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    728\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[33;03m    Return the name of the font that best matches the font properties.\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfindfont\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.family_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/matplotlib/font_manager.py:1615\u001b[39m, in \u001b[36mget_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor)\u001b[39m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hinting_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1613\u001b[39m     hinting_factor = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mtext.hinting_factor\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# must be a tuple to be cached\u001b[39;49;00m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext.kerning_factor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001b[39;49;00m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/matplotlib/font_manager.py:1557\u001b[39m, in \u001b[36m_get_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[39m\n\u001b[32m   1554\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[32m64\u001b[39m)\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_font\u001b[39m(font_filepaths, hinting_factor, *, _kerning_factor, thread_id):\n\u001b[32m   1556\u001b[39m     first_fontpath, *rest = font_filepaths\n\u001b[32m-> \u001b[39m\u001b[32m1557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_fontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fallback_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/hyeonho/Documents/GitHub/iot-dataanalysis-2025/day04/C:/Windows/Fonts/malgun.ttf'"
     ]
    }
   ],
   "source": [
    "# 한글로 Matplotlib 사용시 항상 필요\n",
    "from matplotlib import rcParams, font_manager, rc\n",
    "\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_theme(font='Malgun Gothic', rc={'axes.unicode_minus': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb5cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54984 (\\N{HANGUL SYLLABLE HUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47144 (\\N{HANGUL SYLLABLE RYEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49368 (\\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10개 차트 그리기\n",
    "fig, axes = plt.subplots(1, 10, figsize=(13, 2))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(train_input[i], cmap='gray_r')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.title('Fashion MNIST 훈련 샘플')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb86869",
   "metadata": {},
   "source": [
    "- 이미지는 픽셀당 흑백은 1byte, 컬러는 3~4bytes를 사용\n",
    "- 해상도가 커지면 이미지 파일 사이즈가 기하급수적으로 증가\n",
    "- 28x28 정도로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006619cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.uint8(9),\n",
       " np.uint8(0),\n",
       " np.uint8(0),\n",
       " np.uint8(3),\n",
       " np.uint8(0),\n",
       " np.uint8(2),\n",
       " np.uint8(7),\n",
       " np.uint8(2),\n",
       " np.uint8(5),\n",
       " np.uint8(5)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "[train_target[i] for i in  range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805b003",
   "metadata": {},
   "source": [
    "| 레이블 | 0     | 1    | 2     | 3     | 4    | 5     | 6     | 7        | 8    | 9        |\n",
    "|:------:|:-----:|:----:|:-----:|:-----:|:----:|:-----:|:-----:|:--------:|:----:|:--------:|\n",
    "| 패션MNIST | 티셔츠 | 바지 | 스웨터 | 드레스 | 코트 | 샌달 | 셔츠 | 스니커즈 | 가방 | 앵클부츠 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a3cb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개 데이터에서 각 레이블 별 6000개씩 이미지가 존재\n",
    "np.unique(train_target, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5f6af",
   "metadata": {},
   "source": [
    "#### 사이킷런 머신러닝, 로지스틱회귀로 아이템 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bd118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 모듈 로드\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split    ## 이거 필요없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35432eb9",
   "metadata": {},
   "source": [
    "##### 이미지처리\n",
    "- 28 x 28 2차원 배열을 784 1차원 배열로 변경해줘야 함\n",
    "\n",
    "    <img src='../image/ml0009.png' width='500'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfb41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D 이미지를 1D 벡터(1차원 배열)로 펼치기\n",
    "train_input = train_input.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb345f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ec7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d02910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9cbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링(정규화)\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input.astype(np.float64))\n",
    "test_scaled = scaler.fit_transform(test_input.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cff959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=20, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(C=20, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델\n",
    "lr = LogisticRegression(C = 20, max_iter=1000)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00710c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=20, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=20, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "lr.fit(train_scaled, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e02cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_scaled, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08992970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8317"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "lr.score(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d1d8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_result = lr.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b017d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 이미지와 예측결과 시각화\n",
    "def show_image(index):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(test_input[index].reshape(28, 28), cmap='gray_r')\n",
    "    plt.title(f'실제: {test_target[index]}, 예측: {pred_result[index]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa7a1caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50696 (\\N{HANGUL SYLLABLE YE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/hyeonho/.pyenv/versions/3.11.9/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAADECAYAAAAGYxrSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAACVZJREFUeJzt3VlIVVsYB/DvWGqaiZk5FGYlOKQUgdgAFVQS2ChRREVERERIRfQUPWQgPRQRPQT2EkED1UuZGEIPUVb20EM0CWWkmA1mgzmPl73hXu69+1u3vT1X3P9z/j8QYfl13Of4b7u/tdY+BoaHh4eFCEzEWB8A0UgwuASJwSVIDC5BYnAJEoNLkBhcgsTgEiQGlyAxuASJwf2NnTt3SiAQMH58+PBB0Hz8+FH27Nkjs2bNkpiYGMnMzJRDhw5JW1uboAj4fa/Cy5cvZf78+RIVFaV+va+vT16/fi09PT2u6qwfkhePHz+WhoaGf4xZL9nevXtl5syZ9vF50dnZKQkJCRIdHa1+vb+/X+7cuSMLFixwVbd8+XJP37+jo0Py8/Pt49i3b5+kp6fLs2fPpKKiQvLy8uTp06cSEeH/89l48TkrJIWFhVJbW6t+feHChXaN2zqvFi1aZH/8nfU9urq6ZNu2bZ4fzzqGlJQUaW5uVr++ZcsWGRoacl3nVWVlpTQ2NkpVVZWsXr36r/HExEQ5fvy4HWLrBOB3/v+vNUrq6+ulqalpRP/2ypUr9mXC1q1bxS8aGhocvxk07e3t9mfrP8XfpaWl2Z+tSwcEYRvc3Nxc2bFjh+d/Z/2Kvn79uixevNi+VPCLFStW2B+/s3TpUvtS4MCBA1JXV2ef0aurq6W8vFw2bNggOTk5giBsgztSNTU1dhMzkssEP5gzZ46cP39eXr16ZV8CWde41iWDFfobN24ICt9f446Wkfak1mVCZGSkbN68Wfzk/fv3rmunT59u9wPFxcWSkZEhDx48kLNnz0pSUpKcOnVKEIRtcEfC6shv3bolq1atkilTpgiihw8fypo1a+zLhIKCAnvMukSIj4+XsrIy2bVrl31W9jteKnhw8+bNEc8m+EVFRYXdmP0Z2j+tW7fO/i306NEjQcDgenD58mWJi4uzf8ioPn/+LIODg2rTaRkYGBAEYRtcr9Nhra2tcvfuXSkpKZHY2FjxmwaX02FZWVl2eO/du/eP8atXr9qfEeZwwzq4XqfDrl27Zp+N/usy4dixY/b87r9D4afpsNLSUpk4caKsXbtWjhw5Yl86WPPRZ86ckaKiInvFDgGbMw+XCcnJybJy5cr/bN6s4KampopfZWdn28u6R48elUuXLsmnT59k2rRpcvjwYbs5QxG2wfU6HWbtWfid+/fvy8aNG8dkEv+9h+kwK7xIc7aasA3u/81aSrXW+S9evDjWhxIWIIJrzTlaO6VMv5691o0Gax60t7fXVW1LS4vxOK3ptt27d3uqC0e+39ZIpAnbWQXCxuASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUgMLkFicAkSg0uQGFyCxOASJAaXIDG4BInBJUjjx/oA/OrcuXPq+IsXL1zXejE8POwYCwQCQT9uqOIZlyAxuASJwSVIDC5BYnAJUmBYa2dd6u7uVsdjYmKCeoyoqCgJ1rhx41zXVlVVOcbq6urU2vHjnRMx7969U2vLy8sdY+np6RKswcHBUXkdkPCMS5AYXILE4BIkBpfCrznbtGmTOl5aWuoYW7ZsmfhVcXGxY6ywsFCt1RrHjo4OtTYxMdExlpycrNaWlJQ4xiZNmiTBNmwREaNzbhrr5WiecQkSg0uQGFyCxOASJAaXQnsjeWdnp2OsublZra2srHSMdXV1qbX5+fmuunFLbGysY2xoaEitbWpqcoxduHBBrU1NTXWMJSUlqbW3b992jK1fv16t/fHjh2Osurpara2vr3eMzZ49W60tKipyjGVkZMhoMM1WaK+7aQZjNJadecYlSAwuQWJwCRKDS6G95PvkyRPH2MGDB9XaefPmuV4WnTt3ruv9uNr427dv1drnz587xvr6+tTaJUuWOMZaWlqCbiYHBgZc7ee1fPnyxTH29etXtbatrc0xlpubq9bm5eU5xgoKCtTaqVOnCgqecQkSg0uQGFyCxOASJAaXQntWoaamxjG2f/9+10uSjY2Naq3WOU+ePFmt7e/vd73ZWuv+s7Ky1FptqdK0fKkdr6lWm2349u2bWmtaunarvb1dHddmcyZMmOB6ST0hIUGt1ZaYTZvkc3JyHGPR0dESDJ5xCRKDS5AYXILE4FJoN2e1tbWulkotJ06ccL3UqTUrPT09aq3WKJgaDe0xTMvOmri4ONcNjGkpWTsG03J2fHy868dtVxox0/5hL29npR2vaR+1tpytvTam7QLbt29Xa017m/+NZ1yCxOASJAaXIDG4BInBpdC+y1e7czctLU2t1TZhm5YktTtZZ8yY4bqTNW347u3tDeoNkbU7dC0/f/50jEVGRqq12hKol1kFk1ile09JSVFrtedsmq3QZmhMszbaz9P0s9DeZ+z06dNqLWcVKKQxuASJwSVIDC6FdnOm3U2bmZnpei+s9jdwTW/jZLrI9/IWTBpTrdasmBoYrdEw7S1tbW11Xav9pSJT06cx3RGsPedfv365bkhNtdqSuGmp/s2bN66+lxc84xIkBpcgMbgEicElSAwuhfasgtbRm/7erdaRm5YOtVrT5mVtWdS0gVrbNP5//A1cbUO8aZO8dvevl43dplmFOKWj1957zPRampbftVkB7c5q03PWluRNj1tWVibB4BmXIDG4BInBJUgMLoX2Xb7fv393jJ08edL1Ww+ZliS15szUwGiNhuktjbTGyNQ8aLWmhktbQu3u7na9PGx6bl5eh3ilSTUtZ2vjpufm5S5q7WecnZ3t+i25gsUzLkFicAkSg0uQGFyCxOBSaM8qEPkJz7gEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS5AYXILE4BIkBpcgMbgEicElSAwuQWJwCRKDS4LoD/Wd7wpRKpvAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(11, 17):\n",
    "    show_image(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f904eb",
   "metadata": {},
   "source": [
    "- 여기까지 머신러닝으로 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238da91a",
   "metadata": {},
   "source": [
    "#### 인공신경망\n",
    "\n",
    "- 인간의 뇌 속 뉴런과 유사한 구조로 만든 것\n",
    "- 인공신경망을 이용해서 머신러닝 훈련과 테스트, 예측 등을 수행하는 것\n",
    "- 인공지능 ⊃ 머신러닝 ⊃ 딥러닝(인공신경망)\n",
    "- 정확도가 높아서 딥러닝 가장 많이 사용(트렌드)\n",
    "\n",
    "<img src='../image/ml0010.png' width='700'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce4258e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 모듈 로드\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8add62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdf14e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split() 함수로 기존 훈련세트를 훈련세트:검증세트 8:2로 분리\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f81c6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d64e89",
   "metadata": {},
   "source": [
    "- 기존 훈련 세트 -> 60000\n",
    "- 새 훈련 세트 -> 48000\n",
    "- 검증 세트 -> 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595dfbb",
   "metadata": {},
   "source": [
    "- 밀집층(Dense layer)\n",
    "    - 784픽셀(28*28)을 10개(분류된 아이템 개수) 뉴런을 연결하면 7840개 연결선이 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dddb8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매개변수\n",
    "## 10 출력값(아이템 0~9)\n",
    "## activation 활성화함수 : softmax, sigmoid, ReLU...\n",
    "## 입력크기 : 28*28\n",
    "dense = keras.layers.Dense(10, activation='softmax', input_shape=(784, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6029caa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dense' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/keras/src/models/sequential.py:74\u001b[39m, in \u001b[36mSequential.__init__\u001b[39m\u001b[34m(self, layers, trainable, name)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m._layers = []\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m layers:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._maybe_rebuild()\n",
      "\u001b[31mTypeError\u001b[39m: 'Dense' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf3c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련전 설정\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88125da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4211 - accuracy: 0.8631\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4201 - accuracy: 0.8626\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4197 - accuracy: 0.8631\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.4185 - accuracy: 0.8634\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4187 - accuracy: 0.8625\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4179 - accuracy: 0.8645\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4183 - accuracy: 0.8639\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 1s 875us/step - loss: 0.4151 - accuracy: 0.8651\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4167 - accuracy: 0.8648\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.4144 - accuracy: 0.8661\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.4157 - accuracy: 0.8670\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4162 - accuracy: 0.8658\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4157 - accuracy: 0.8659\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4135 - accuracy: 0.8651\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4134 - accuracy: 0.8657\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4139 - accuracy: 0.8658\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.4129 - accuracy: 0.8666\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4134 - accuracy: 0.8669\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4139 - accuracy: 0.8671\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4129 - accuracy: 0.8663\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4126 - accuracy: 0.8666\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4111 - accuracy: 0.8676\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4132 - accuracy: 0.8666\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4102 - accuracy: 0.8683\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4129 - accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4107 - accuracy: 0.8687\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4121 - accuracy: 0.8680\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4105 - accuracy: 0.8681\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4095 - accuracy: 0.8697\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4099 - accuracy: 0.8678\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.4100 - accuracy: 0.8694\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4092 - accuracy: 0.8672\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4099 - accuracy: 0.8687\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4098 - accuracy: 0.8687\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.4104 - accuracy: 0.8703\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4094 - accuracy: 0.8690\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4090 - accuracy: 0.8689\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4106 - accuracy: 0.8682\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 1s 814us/step - loss: 0.4094 - accuracy: 0.8690\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.4102 - accuracy: 0.8700\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4101 - accuracy: 0.8693\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4087 - accuracy: 0.8685\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4102 - accuracy: 0.8683\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.4083 - accuracy: 0.8693\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4100 - accuracy: 0.8693\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4100 - accuracy: 0.8691\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4105 - accuracy: 0.8693\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.4086 - accuracy: 0.8700\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4092 - accuracy: 0.8698\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4103 - accuracy: 0.8692\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4090 - accuracy: 0.8699\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4089 - accuracy: 0.8702\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4085 - accuracy: 0.8694\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4079 - accuracy: 0.8691\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4087 - accuracy: 0.8713\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4101 - accuracy: 0.8692\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4098 - accuracy: 0.8689\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4100 - accuracy: 0.8706\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.4112 - accuracy: 0.8709\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4091 - accuracy: 0.8697\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4095 - accuracy: 0.8694\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4111 - accuracy: 0.8707\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4106 - accuracy: 0.8704\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4086 - accuracy: 0.8702\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4102 - accuracy: 0.8699\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4070 - accuracy: 0.8715\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4095 - accuracy: 0.8697\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4085 - accuracy: 0.8701\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4087 - accuracy: 0.8703\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4095 - accuracy: 0.8708\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.4092 - accuracy: 0.8713\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4080 - accuracy: 0.8705\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 0.4088 - accuracy: 0.8713\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4098 - accuracy: 0.8709\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4100 - accuracy: 0.8716\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4090 - accuracy: 0.8702\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4083 - accuracy: 0.8711\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4097 - accuracy: 0.8722\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4092 - accuracy: 0.8713\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4081 - accuracy: 0.8714\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4081 - accuracy: 0.8720\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4098 - accuracy: 0.8707\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4084 - accuracy: 0.8711\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4064 - accuracy: 0.8708\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4094 - accuracy: 0.8715\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4097 - accuracy: 0.8724\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4084 - accuracy: 0.8728\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4079 - accuracy: 0.8719\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4091 - accuracy: 0.8709\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4077 - accuracy: 0.8704\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4078 - accuracy: 0.8711\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4084 - accuracy: 0.8699\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4085 - accuracy: 0.8721\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4080 - accuracy: 0.8708\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4073 - accuracy: 0.8714\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 0.4097 - accuracy: 0.8707\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4084 - accuracy: 0.8713\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4081 - accuracy: 0.8711\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 1s 916us/step - loss: 0.4077 - accuracy: 0.8712\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 0.4070 - accuracy: 0.8719\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4091 - accuracy: 0.8713\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4083 - accuracy: 0.8709\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4094 - accuracy: 0.8704\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4077 - accuracy: 0.8714\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4085 - accuracy: 0.8720\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.4086 - accuracy: 0.8701\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4077 - accuracy: 0.8720\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4096 - accuracy: 0.8707\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4096 - accuracy: 0.8717\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4092 - accuracy: 0.8720\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4100 - accuracy: 0.8722\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 1s 888us/step - loss: 0.4088 - accuracy: 0.8712\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4092 - accuracy: 0.8721\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4088 - accuracy: 0.8703\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4093 - accuracy: 0.8721\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.4078 - accuracy: 0.8714\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4080 - accuracy: 0.8710\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.4098 - accuracy: 0.8716\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4085 - accuracy: 0.8716\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4092 - accuracy: 0.8726\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4089 - accuracy: 0.8727\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4101 - accuracy: 0.8722\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4093 - accuracy: 0.8713\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4091 - accuracy: 0.8714\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 0.4092 - accuracy: 0.8725\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4102 - accuracy: 0.8725\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4086 - accuracy: 0.8720\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4108 - accuracy: 0.8714\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4100 - accuracy: 0.8712\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4095 - accuracy: 0.8716\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4099 - accuracy: 0.8715\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4101 - accuracy: 0.8727\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4115 - accuracy: 0.8725\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4101 - accuracy: 0.8716\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4094 - accuracy: 0.8720\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4110 - accuracy: 0.8723\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4108 - accuracy: 0.8711\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4092 - accuracy: 0.8720\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4098 - accuracy: 0.8716\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4103 - accuracy: 0.8729\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4107 - accuracy: 0.8709\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4110 - accuracy: 0.8709\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4098 - accuracy: 0.8722\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 0.4099 - accuracy: 0.8713\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4100 - accuracy: 0.8736\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4094 - accuracy: 0.8714\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 0.4093 - accuracy: 0.8730\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4095 - accuracy: 0.8719\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4093 - accuracy: 0.8704\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4092 - accuracy: 0.8721\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4110 - accuracy: 0.8715\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4100 - accuracy: 0.8725\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 0.4101 - accuracy: 0.8717\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4099 - accuracy: 0.8725\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4099 - accuracy: 0.8716\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4123 - accuracy: 0.8707\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4099 - accuracy: 0.8723\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4106 - accuracy: 0.8713\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4106 - accuracy: 0.8719\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4098 - accuracy: 0.8724\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4108 - accuracy: 0.8723\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4118 - accuracy: 0.8728\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4099 - accuracy: 0.8727\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4119 - accuracy: 0.8712\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4087 - accuracy: 0.8721\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4123 - accuracy: 0.8717\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4102 - accuracy: 0.8734\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 0.4110 - accuracy: 0.8707\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4113 - accuracy: 0.8724\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4091 - accuracy: 0.8714\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4105 - accuracy: 0.8710\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4100 - accuracy: 0.8728\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4106 - accuracy: 0.8723\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4098 - accuracy: 0.8725\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4112 - accuracy: 0.8721\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4108 - accuracy: 0.8733\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4107 - accuracy: 0.8724\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4109 - accuracy: 0.8730\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4102 - accuracy: 0.8731\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4109 - accuracy: 0.8719\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4115 - accuracy: 0.8737\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4106 - accuracy: 0.8738\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4094 - accuracy: 0.8728\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4107 - accuracy: 0.8723\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4116 - accuracy: 0.8721\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4130 - accuracy: 0.8717\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4103 - accuracy: 0.8745\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4105 - accuracy: 0.8714\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4094 - accuracy: 0.8718\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 0.4090 - accuracy: 0.8724\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4111 - accuracy: 0.8721\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4116 - accuracy: 0.8729\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4125 - accuracy: 0.8714\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4115 - accuracy: 0.8727\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4123 - accuracy: 0.8731\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4119 - accuracy: 0.8721\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4114 - accuracy: 0.8728\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4118 - accuracy: 0.8723\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4114 - accuracy: 0.8714\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 1s 882us/step - loss: 0.4117 - accuracy: 0.8714\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.4119 - accuracy: 0.8704\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4109 - accuracy: 0.8735\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.4107 - accuracy: 0.8739\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4121 - accuracy: 0.8727\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4119 - accuracy: 0.8728\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4111 - accuracy: 0.8721\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4097 - accuracy: 0.8735\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4117 - accuracy: 0.8724\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4137 - accuracy: 0.8727\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4119 - accuracy: 0.8715\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4127 - accuracy: 0.8724\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4117 - accuracy: 0.8729\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4131 - accuracy: 0.8716\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4122 - accuracy: 0.8724\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 0.4115 - accuracy: 0.8737\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4119 - accuracy: 0.8721\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4135 - accuracy: 0.8725\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4115 - accuracy: 0.8724\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4118 - accuracy: 0.8724\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4127 - accuracy: 0.8725\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.4127 - accuracy: 0.8724\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4117 - accuracy: 0.8733\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4125 - accuracy: 0.8715\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4113 - accuracy: 0.8721\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4131 - accuracy: 0.8719\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4135 - accuracy: 0.8724\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4136 - accuracy: 0.8727\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4119 - accuracy: 0.8720\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 0.4112 - accuracy: 0.8720\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.4137 - accuracy: 0.8733\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4112 - accuracy: 0.8723\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4109 - accuracy: 0.8721\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4120 - accuracy: 0.8732\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4118 - accuracy: 0.8727\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4126 - accuracy: 0.8727\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4132 - accuracy: 0.8728\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4137 - accuracy: 0.8721\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4134 - accuracy: 0.8732\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4143 - accuracy: 0.8726\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 0.4123 - accuracy: 0.8716\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4137 - accuracy: 0.8738\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4134 - accuracy: 0.8716\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4137 - accuracy: 0.8719\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 1s 847us/step - loss: 0.4127 - accuracy: 0.8727\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4115 - accuracy: 0.8724\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 0.4128 - accuracy: 0.8715\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4136 - accuracy: 0.8725\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4123 - accuracy: 0.8736\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4126 - accuracy: 0.8728\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 0.4128 - accuracy: 0.8731\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 0.4125 - accuracy: 0.8746\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4136 - accuracy: 0.8711\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4142 - accuracy: 0.8723\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.4143 - accuracy: 0.8734\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4147 - accuracy: 0.8734\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4148 - accuracy: 0.8714\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4141 - accuracy: 0.8734\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.4158 - accuracy: 0.8727\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4138 - accuracy: 0.8730\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4138 - accuracy: 0.8734\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4151 - accuracy: 0.8736\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4135 - accuracy: 0.8728\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4126 - accuracy: 0.8737\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.4128 - accuracy: 0.8723\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 0.4134 - accuracy: 0.8731\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4131 - accuracy: 0.8738\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4132 - accuracy: 0.8731\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4128 - accuracy: 0.8739\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4123 - accuracy: 0.8731\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4110 - accuracy: 0.8721\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.4123 - accuracy: 0.8734\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4123 - accuracy: 0.8735\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 0.4143 - accuracy: 0.8724\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4119 - accuracy: 0.8730\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4123 - accuracy: 0.8731\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4122 - accuracy: 0.8741\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4133 - accuracy: 0.8723\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.4129 - accuracy: 0.8741\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.4132 - accuracy: 0.8727\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 1s 814us/step - loss: 0.4119 - accuracy: 0.8733\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4139 - accuracy: 0.8739\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4140 - accuracy: 0.8719\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4143 - accuracy: 0.8716\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4130 - accuracy: 0.8728\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4139 - accuracy: 0.8729\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4128 - accuracy: 0.8729\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4138 - accuracy: 0.8727\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4121 - accuracy: 0.8728\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 0.4138 - accuracy: 0.8721\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4139 - accuracy: 0.8721\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4146 - accuracy: 0.8730\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4141 - accuracy: 0.8730\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.4150 - accuracy: 0.8715\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 0.4138 - accuracy: 0.8730\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4144 - accuracy: 0.8716\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 0.4131 - accuracy: 0.8730\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4147 - accuracy: 0.8721\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4146 - accuracy: 0.8726\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 0.4142 - accuracy: 0.8735\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 1s 927us/step - loss: 0.4137 - accuracy: 0.8735\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4129 - accuracy: 0.8733\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4143 - accuracy: 0.8739\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4135 - accuracy: 0.8737\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4136 - accuracy: 0.8737\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4130 - accuracy: 0.8737\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4133 - accuracy: 0.8746\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4136 - accuracy: 0.8736\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4129 - accuracy: 0.8732\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4137 - accuracy: 0.8724\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4142 - accuracy: 0.8747\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4159 - accuracy: 0.8735\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4143 - accuracy: 0.8736\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4143 - accuracy: 0.8734\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4121 - accuracy: 0.8743\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4138 - accuracy: 0.8725\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 1s 914us/step - loss: 0.4132 - accuracy: 0.8743\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 1s 902us/step - loss: 0.4135 - accuracy: 0.8739\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 0.4131 - accuracy: 0.8730\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4131 - accuracy: 0.8724\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4150 - accuracy: 0.8721\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 0.4144 - accuracy: 0.8728\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4136 - accuracy: 0.8729\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4135 - accuracy: 0.8740\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4143 - accuracy: 0.8725\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.4144 - accuracy: 0.8723\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4126 - accuracy: 0.8724\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4142 - accuracy: 0.8739\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4141 - accuracy: 0.8725\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4158 - accuracy: 0.8731\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4149 - accuracy: 0.8735\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4150 - accuracy: 0.8735\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 1s 847us/step - loss: 0.4152 - accuracy: 0.8733\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4149 - accuracy: 0.8750\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4142 - accuracy: 0.8735\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4150 - accuracy: 0.8740\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4150 - accuracy: 0.8730\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.4137 - accuracy: 0.8747\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.4143 - accuracy: 0.8731\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 0.4155 - accuracy: 0.8721\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4149 - accuracy: 0.8727\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4153 - accuracy: 0.8748\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4141 - accuracy: 0.8734\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4142 - accuracy: 0.8734\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.4158 - accuracy: 0.8741\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.4171 - accuracy: 0.8720\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4151 - accuracy: 0.8737\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.4156 - accuracy: 0.8737\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4177 - accuracy: 0.8736\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4172 - accuracy: 0.8740\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4174 - accuracy: 0.8731\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4178 - accuracy: 0.8732\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4194 - accuracy: 0.8723\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4167 - accuracy: 0.8732\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4176 - accuracy: 0.8724\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4178 - accuracy: 0.8741\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4176 - accuracy: 0.8729\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 0.4173 - accuracy: 0.8730\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4161 - accuracy: 0.8736\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4166 - accuracy: 0.8734\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4167 - accuracy: 0.8730\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4169 - accuracy: 0.8735\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.4175 - accuracy: 0.8740\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4178 - accuracy: 0.8737\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 0.4198 - accuracy: 0.8740\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4190 - accuracy: 0.8734\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.4180 - accuracy: 0.8745\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4158 - accuracy: 0.8740\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4177 - accuracy: 0.8743\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4174 - accuracy: 0.8726\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4150 - accuracy: 0.8745\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4176 - accuracy: 0.8741\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4180 - accuracy: 0.8729\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 0.4178 - accuracy: 0.8727\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 0.4163 - accuracy: 0.8740\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.4177 - accuracy: 0.8735\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.4177 - accuracy: 0.8733\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4192 - accuracy: 0.8737\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 0.4171 - accuracy: 0.8737\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4175 - accuracy: 0.8731\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 0.4187 - accuracy: 0.8742\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.4185 - accuracy: 0.8736\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4172 - accuracy: 0.8741\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.4191 - accuracy: 0.8731\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4187 - accuracy: 0.8730\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4183 - accuracy: 0.8724\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4180 - accuracy: 0.8730\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4174 - accuracy: 0.8723\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4173 - accuracy: 0.8731\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4189 - accuracy: 0.8738\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4184 - accuracy: 0.8731\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4177 - accuracy: 0.8738\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4191 - accuracy: 0.8740\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4183 - accuracy: 0.8728\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 0.4173 - accuracy: 0.8746\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4176 - accuracy: 0.8737\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4199 - accuracy: 0.8739\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.4203 - accuracy: 0.8732\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.4197 - accuracy: 0.8729\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4173 - accuracy: 0.8738\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4186 - accuracy: 0.8735\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4179 - accuracy: 0.8735\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4191 - accuracy: 0.8737\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4183 - accuracy: 0.8739\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4181 - accuracy: 0.8737\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4194 - accuracy: 0.8736\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4185 - accuracy: 0.8740\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4189 - accuracy: 0.8739\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4184 - accuracy: 0.8732\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4189 - accuracy: 0.8736\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 0.4204 - accuracy: 0.8747\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.4188 - accuracy: 0.8728\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4175 - accuracy: 0.8731\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.4191 - accuracy: 0.8732\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4175 - accuracy: 0.8735\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.4184 - accuracy: 0.8731\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4195 - accuracy: 0.8726\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4191 - accuracy: 0.8743\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4187 - accuracy: 0.8740\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4175 - accuracy: 0.8733\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4205 - accuracy: 0.8744\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4195 - accuracy: 0.8733\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4184 - accuracy: 0.8741\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4207 - accuracy: 0.8737\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4190 - accuracy: 0.8729\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4192 - accuracy: 0.8735\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4178 - accuracy: 0.8737\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4180 - accuracy: 0.8733\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4197 - accuracy: 0.8729\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4194 - accuracy: 0.8734\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4192 - accuracy: 0.8730\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4192 - accuracy: 0.8738\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4214 - accuracy: 0.8724\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4177 - accuracy: 0.8737\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4215 - accuracy: 0.8739\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4212 - accuracy: 0.8741\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 1s 814us/step - loss: 0.4214 - accuracy: 0.8727\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4202 - accuracy: 0.8755\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4211 - accuracy: 0.8742\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4202 - accuracy: 0.8741\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 0.4206 - accuracy: 0.8737\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4183 - accuracy: 0.8758\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 0.4221 - accuracy: 0.8748\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 0.4216 - accuracy: 0.8747\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4215 - accuracy: 0.8740\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4201 - accuracy: 0.8725\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.4204 - accuracy: 0.8738\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4206 - accuracy: 0.8738\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 0.4193 - accuracy: 0.8740\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4199 - accuracy: 0.8735\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4201 - accuracy: 0.8743\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4205 - accuracy: 0.8723\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4206 - accuracy: 0.8741\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 0.4197 - accuracy: 0.8735\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.4209 - accuracy: 0.8738\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4188 - accuracy: 0.8739\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4211 - accuracy: 0.8727\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4196 - accuracy: 0.8726\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.4200 - accuracy: 0.8740\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4206 - accuracy: 0.8746\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4196 - accuracy: 0.8739\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4218 - accuracy: 0.8725\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4188 - accuracy: 0.8733\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4201 - accuracy: 0.8728\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.4203 - accuracy: 0.8732\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.4179 - accuracy: 0.8746\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4191 - accuracy: 0.8743\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4185 - accuracy: 0.8725\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.4196 - accuracy: 0.8725\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4200 - accuracy: 0.8730\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4193 - accuracy: 0.8726\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4188 - accuracy: 0.8737\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4189 - accuracy: 0.8736\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 1s 884us/step - loss: 0.4188 - accuracy: 0.8729\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 0.4199 - accuracy: 0.8739\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4197 - accuracy: 0.8737\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4213 - accuracy: 0.8728\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4190 - accuracy: 0.8726\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4201 - accuracy: 0.8744\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4188 - accuracy: 0.8753\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.4198 - accuracy: 0.8743\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4217 - accuracy: 0.8747\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4189 - accuracy: 0.8739\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4196 - accuracy: 0.8741\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 0.4193 - accuracy: 0.8737\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4183 - accuracy: 0.8733\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4216 - accuracy: 0.8738\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4203 - accuracy: 0.8732\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4197 - accuracy: 0.8734\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4187 - accuracy: 0.8734\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4194 - accuracy: 0.8739\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4186 - accuracy: 0.8734\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4219 - accuracy: 0.8739\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4212 - accuracy: 0.8734\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4207 - accuracy: 0.8733\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4204 - accuracy: 0.8736\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4213 - accuracy: 0.8741\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.4201 - accuracy: 0.8745\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4200 - accuracy: 0.8737\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4209 - accuracy: 0.8741\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4206 - accuracy: 0.8741\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.4224 - accuracy: 0.8731\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 0.4223 - accuracy: 0.8730\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4217 - accuracy: 0.8730\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4228 - accuracy: 0.8733\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4214 - accuracy: 0.8731\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.4222 - accuracy: 0.8731\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4213 - accuracy: 0.8743\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4226 - accuracy: 0.8734\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4225 - accuracy: 0.8737\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4218 - accuracy: 0.8750\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.4220 - accuracy: 0.8740\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.4200 - accuracy: 0.8740\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4200 - accuracy: 0.8749\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4224 - accuracy: 0.8739\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4223 - accuracy: 0.8733\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.4222 - accuracy: 0.8730\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.4212 - accuracy: 0.8732\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4218 - accuracy: 0.8739\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4235 - accuracy: 0.8727\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.4222 - accuracy: 0.8742\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.4248 - accuracy: 0.8733\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4240 - accuracy: 0.8733\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4213 - accuracy: 0.8747\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4223 - accuracy: 0.8754\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4235 - accuracy: 0.8725\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4220 - accuracy: 0.8749\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4234 - accuracy: 0.8725\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4223 - accuracy: 0.8746\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 0.4223 - accuracy: 0.8746\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4226 - accuracy: 0.8750\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 0.4216 - accuracy: 0.8740\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.4217 - accuracy: 0.8735\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 0.4223 - accuracy: 0.8736\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4225 - accuracy: 0.8739\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4222 - accuracy: 0.8735\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.4210 - accuracy: 0.8736\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4226 - accuracy: 0.8736\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 0.4226 - accuracy: 0.8737\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4217 - accuracy: 0.8740\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4245 - accuracy: 0.8734\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4240 - accuracy: 0.8744\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4243 - accuracy: 0.8741\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4238 - accuracy: 0.8730\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.4237 - accuracy: 0.8744\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.4227 - accuracy: 0.8736\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4218 - accuracy: 0.8751\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4229 - accuracy: 0.8738\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4211 - accuracy: 0.8741\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4223 - accuracy: 0.8743\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4224 - accuracy: 0.8737\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4214 - accuracy: 0.8734\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.4215 - accuracy: 0.8746\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4220 - accuracy: 0.8746\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 0.4219 - accuracy: 0.8749\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4227 - accuracy: 0.8734\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 0.4230 - accuracy: 0.8738\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 0.4232 - accuracy: 0.8731\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4222 - accuracy: 0.8740\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.4216 - accuracy: 0.8742\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.4214 - accuracy: 0.8745\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4230 - accuracy: 0.8745\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4217 - accuracy: 0.8741\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4230 - accuracy: 0.8736\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4230 - accuracy: 0.8742\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4226 - accuracy: 0.8743\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4230 - accuracy: 0.8749\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4234 - accuracy: 0.8744\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.4246 - accuracy: 0.8733\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4234 - accuracy: 0.8743\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4240 - accuracy: 0.8750\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4238 - accuracy: 0.8744\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.4241 - accuracy: 0.8736\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4247 - accuracy: 0.8734\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4243 - accuracy: 0.8733\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4236 - accuracy: 0.8726\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4239 - accuracy: 0.8728\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4238 - accuracy: 0.8735\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4229 - accuracy: 0.8733\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4218 - accuracy: 0.8738\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4239 - accuracy: 0.8751\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4244 - accuracy: 0.8737\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4243 - accuracy: 0.8730\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4243 - accuracy: 0.8737\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4239 - accuracy: 0.8735\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4231 - accuracy: 0.8748\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4246 - accuracy: 0.8743\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4233 - accuracy: 0.8737\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4250 - accuracy: 0.8727\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 0.4241 - accuracy: 0.8738\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4239 - accuracy: 0.8739\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4237 - accuracy: 0.8742\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4255 - accuracy: 0.8729\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 0.4239 - accuracy: 0.8742\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4232 - accuracy: 0.8744\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4245 - accuracy: 0.8741\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4254 - accuracy: 0.8744\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4228 - accuracy: 0.8736\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4242 - accuracy: 0.8762\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 0.4222 - accuracy: 0.8737\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4231 - accuracy: 0.8754\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4232 - accuracy: 0.8754\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4239 - accuracy: 0.8740\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.4243 - accuracy: 0.8744\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4240 - accuracy: 0.8746\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4233 - accuracy: 0.8749\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4246 - accuracy: 0.8731\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4231 - accuracy: 0.8726\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.4241 - accuracy: 0.8741\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4247 - accuracy: 0.8739\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4232 - accuracy: 0.8739\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4228 - accuracy: 0.8736\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.4243 - accuracy: 0.8745\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4223 - accuracy: 0.8741\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4245 - accuracy: 0.8736\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 1s 895us/step - loss: 0.4221 - accuracy: 0.8741\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4234 - accuracy: 0.8751\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4229 - accuracy: 0.8750\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4236 - accuracy: 0.8749\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4236 - accuracy: 0.8742\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.4250 - accuracy: 0.8744\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4255 - accuracy: 0.8746\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4231 - accuracy: 0.8757\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4253 - accuracy: 0.8737\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.4250 - accuracy: 0.8748\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4237 - accuracy: 0.8745\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4249 - accuracy: 0.8739\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4249 - accuracy: 0.8740\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.4258 - accuracy: 0.8733\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 0.4245 - accuracy: 0.8754\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.4258 - accuracy: 0.8742\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 0.4241 - accuracy: 0.8739\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.4255 - accuracy: 0.8736\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4231 - accuracy: 0.8748\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4247 - accuracy: 0.8751\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4242 - accuracy: 0.8743\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 0.4242 - accuracy: 0.8741\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4242 - accuracy: 0.8737\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.4232 - accuracy: 0.8729\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4224 - accuracy: 0.8749\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4230 - accuracy: 0.8748\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4251 - accuracy: 0.8730\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.4242 - accuracy: 0.8745\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.4233 - accuracy: 0.8739\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4231 - accuracy: 0.8740\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.4232 - accuracy: 0.8743\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 0.4235 - accuracy: 0.8746\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4245 - accuracy: 0.8739\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4238 - accuracy: 0.8737\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 1s 920us/step - loss: 0.4243 - accuracy: 0.8749\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4237 - accuracy: 0.8749\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4228 - accuracy: 0.8751\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4230 - accuracy: 0.8738\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4223 - accuracy: 0.8745\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.4241 - accuracy: 0.8742\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 0.4246 - accuracy: 0.8742\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4251 - accuracy: 0.8741\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4242 - accuracy: 0.8744\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4253 - accuracy: 0.8750\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4242 - accuracy: 0.8742\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4226 - accuracy: 0.8745\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4248 - accuracy: 0.8744\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 0.4251 - accuracy: 0.8735\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.4230 - accuracy: 0.8742\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4241 - accuracy: 0.8737\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.4255 - accuracy: 0.8748\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 0.4254 - accuracy: 0.8728\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 0.4267 - accuracy: 0.8739\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4251 - accuracy: 0.8745\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 0.4246 - accuracy: 0.8760\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 0.4256 - accuracy: 0.8763\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4244 - accuracy: 0.8730\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4251 - accuracy: 0.8740\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4265 - accuracy: 0.8744\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 1s 958us/step - loss: 0.4244 - accuracy: 0.8736\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 1s 955us/step - loss: 0.4246 - accuracy: 0.8748\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 1s 895us/step - loss: 0.4254 - accuracy: 0.8745\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 1s 847us/step - loss: 0.4234 - accuracy: 0.8740\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4234 - accuracy: 0.8742\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 0.4249 - accuracy: 0.8741\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4244 - accuracy: 0.8745\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4245 - accuracy: 0.8748\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 1s 814us/step - loss: 0.4244 - accuracy: 0.8749\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4246 - accuracy: 0.8747\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4254 - accuracy: 0.8741\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4259 - accuracy: 0.8751\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.4261 - accuracy: 0.8742\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 0.4254 - accuracy: 0.8749\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4264 - accuracy: 0.8736\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.4258 - accuracy: 0.8741\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.4244 - accuracy: 0.8745\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 0.4268 - accuracy: 0.8749\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4250 - accuracy: 0.8749\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4252 - accuracy: 0.8740\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4262 - accuracy: 0.8742\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.4268 - accuracy: 0.8742\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.4263 - accuracy: 0.8738\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.4251 - accuracy: 0.8759\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.4269 - accuracy: 0.8739\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 0.4269 - accuracy: 0.8733\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 0.4274 - accuracy: 0.8743\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4277 - accuracy: 0.8740\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4283 - accuracy: 0.8742\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 0.4266 - accuracy: 0.8736\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4258 - accuracy: 0.8746\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4257 - accuracy: 0.8746\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4253 - accuracy: 0.8741\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4261 - accuracy: 0.8740\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4269 - accuracy: 0.8750\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4266 - accuracy: 0.8743\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 0.4266 - accuracy: 0.8747\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4279 - accuracy: 0.8754\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4261 - accuracy: 0.8745\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4267 - accuracy: 0.8734\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4268 - accuracy: 0.8733\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4258 - accuracy: 0.8746\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4250 - accuracy: 0.8742\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4249 - accuracy: 0.8746\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4258 - accuracy: 0.8745\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4249 - accuracy: 0.8751\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4262 - accuracy: 0.8745\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.4250 - accuracy: 0.8749\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4242 - accuracy: 0.8735\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 0.4261 - accuracy: 0.8730\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4260 - accuracy: 0.8738\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4253 - accuracy: 0.8749\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4255 - accuracy: 0.8754\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4262 - accuracy: 0.8740\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4277 - accuracy: 0.8748\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4241 - accuracy: 0.8745\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4255 - accuracy: 0.8749\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4252 - accuracy: 0.8754\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 1s 902us/step - loss: 0.4253 - accuracy: 0.8741\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4259 - accuracy: 0.8740\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4265 - accuracy: 0.8741\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4265 - accuracy: 0.8742\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4258 - accuracy: 0.8735\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4259 - accuracy: 0.8734\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4257 - accuracy: 0.8744\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4248 - accuracy: 0.8746\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4267 - accuracy: 0.8744\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4253 - accuracy: 0.8742\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4264 - accuracy: 0.8754\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.4256 - accuracy: 0.8739\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 0.4259 - accuracy: 0.8751\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 1s 879us/step - loss: 0.4259 - accuracy: 0.8748\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4251 - accuracy: 0.8758\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.4239 - accuracy: 0.8740\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.4260 - accuracy: 0.8750\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4261 - accuracy: 0.8744\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4261 - accuracy: 0.8759\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4262 - accuracy: 0.8734\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4278 - accuracy: 0.8762\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4265 - accuracy: 0.8736\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.4263 - accuracy: 0.8742\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4266 - accuracy: 0.8749\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4270 - accuracy: 0.8754\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4273 - accuracy: 0.8759\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.4254 - accuracy: 0.8748\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4254 - accuracy: 0.8750\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4269 - accuracy: 0.8743\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4258 - accuracy: 0.8745\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4246 - accuracy: 0.8735\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4281 - accuracy: 0.8752\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4269 - accuracy: 0.8757\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4261 - accuracy: 0.8749\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4273 - accuracy: 0.8751\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4262 - accuracy: 0.8750\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4276 - accuracy: 0.8740\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 0.4259 - accuracy: 0.8728\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 1s 847us/step - loss: 0.4255 - accuracy: 0.8751\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 0.4251 - accuracy: 0.8739\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4261 - accuracy: 0.8749\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4268 - accuracy: 0.8738\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4273 - accuracy: 0.8747\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.4279 - accuracy: 0.8739\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4262 - accuracy: 0.8749\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.4267 - accuracy: 0.8748\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4258 - accuracy: 0.8740\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4252 - accuracy: 0.8748\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4245 - accuracy: 0.8745\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4253 - accuracy: 0.8746\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4264 - accuracy: 0.8764\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4254 - accuracy: 0.8731\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4254 - accuracy: 0.8754\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4248 - accuracy: 0.8742\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4251 - accuracy: 0.8747\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4253 - accuracy: 0.8741\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4243 - accuracy: 0.8750\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4260 - accuracy: 0.8748\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4253 - accuracy: 0.8737\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4250 - accuracy: 0.8751\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.4257 - accuracy: 0.8744\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4263 - accuracy: 0.8738\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4264 - accuracy: 0.8743\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4253 - accuracy: 0.8743\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4249 - accuracy: 0.8738\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4264 - accuracy: 0.8745\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4255 - accuracy: 0.8737\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4242 - accuracy: 0.8748\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4256 - accuracy: 0.8741\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4264 - accuracy: 0.8753\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 0.4264 - accuracy: 0.8745\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4272 - accuracy: 0.8742\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4259 - accuracy: 0.8745\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4241 - accuracy: 0.8743\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4256 - accuracy: 0.8752\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 0.4256 - accuracy: 0.8726\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4275 - accuracy: 0.8743\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.4269 - accuracy: 0.8735\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.4273 - accuracy: 0.8735\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4283 - accuracy: 0.8748\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 1s 862us/step - loss: 0.4268 - accuracy: 0.8742\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 0.4262 - accuracy: 0.8735\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 1s 884us/step - loss: 0.4272 - accuracy: 0.8742\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4270 - accuracy: 0.8750\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 1s 927us/step - loss: 0.4264 - accuracy: 0.8736\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.4256 - accuracy: 0.8761\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4261 - accuracy: 0.8741\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 0.4263 - accuracy: 0.8746\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4282 - accuracy: 0.8743\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4273 - accuracy: 0.8739\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.4263 - accuracy: 0.8745\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.4258 - accuracy: 0.8743\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 0.4274 - accuracy: 0.8739\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4275 - accuracy: 0.8741\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.4270 - accuracy: 0.8740\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4263 - accuracy: 0.8747\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 0.4262 - accuracy: 0.8743\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4245 - accuracy: 0.8749\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 0.4280 - accuracy: 0.8740\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4256 - accuracy: 0.8751\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4265 - accuracy: 0.8747\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4257 - accuracy: 0.8748\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 1s 942us/step - loss: 0.4278 - accuracy: 0.8738\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4271 - accuracy: 0.8746\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 1s 899us/step - loss: 0.4257 - accuracy: 0.8744\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 1s 875us/step - loss: 0.4261 - accuracy: 0.8749\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4271 - accuracy: 0.8745\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.4264 - accuracy: 0.8743\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.4263 - accuracy: 0.8752\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 0.4262 - accuracy: 0.8742\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 0.4267 - accuracy: 0.8748\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.4269 - accuracy: 0.8744\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4279 - accuracy: 0.8738\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.4275 - accuracy: 0.8743\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4276 - accuracy: 0.8751\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 0.4255 - accuracy: 0.8753\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4286 - accuracy: 0.8748\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.4263 - accuracy: 0.8733\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4269 - accuracy: 0.8747\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 1s 875us/step - loss: 0.4268 - accuracy: 0.8752\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4270 - accuracy: 0.8752\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4264 - accuracy: 0.8754\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4270 - accuracy: 0.8751\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.4275 - accuracy: 0.8745\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4262 - accuracy: 0.8749\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4267 - accuracy: 0.8751\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4272 - accuracy: 0.8749\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4277 - accuracy: 0.8741\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4280 - accuracy: 0.8756\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.4264 - accuracy: 0.8746\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.4264 - accuracy: 0.8750\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 0.4272 - accuracy: 0.8734\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.4265 - accuracy: 0.8738\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 0.4269 - accuracy: 0.8746\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4262 - accuracy: 0.8741\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4266 - accuracy: 0.8744\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 0.4274 - accuracy: 0.8748\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 1s 901us/step - loss: 0.4262 - accuracy: 0.8739\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 1s 892us/step - loss: 0.4271 - accuracy: 0.8753\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 1s 891us/step - loss: 0.4279 - accuracy: 0.8749\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 1s 893us/step - loss: 0.4270 - accuracy: 0.8741\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4273 - accuracy: 0.8735\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.4283 - accuracy: 0.8746\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4277 - accuracy: 0.8743\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 0.4274 - accuracy: 0.8741\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.4279 - accuracy: 0.8745\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4276 - accuracy: 0.8749\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4283 - accuracy: 0.8741\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.4287 - accuracy: 0.8747\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4283 - accuracy: 0.8756\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 1s 850us/step - loss: 0.4282 - accuracy: 0.8761\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4275 - accuracy: 0.8755\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.4270 - accuracy: 0.8747\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 1s 838us/step - loss: 0.4268 - accuracy: 0.8742\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 0.4263 - accuracy: 0.8753\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4262 - accuracy: 0.8746\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.4276 - accuracy: 0.8739\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 0.4273 - accuracy: 0.8749\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 0.4271 - accuracy: 0.8747\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4281 - accuracy: 0.8749\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4279 - accuracy: 0.8759\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4266 - accuracy: 0.8748\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.4278 - accuracy: 0.8744\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4274 - accuracy: 0.8739\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4260 - accuracy: 0.8751\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.4278 - accuracy: 0.8750\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.4273 - accuracy: 0.8746\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 1s 872us/step - loss: 0.4271 - accuracy: 0.8742\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 0.4261 - accuracy: 0.8754\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 0.4277 - accuracy: 0.8755\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.4282 - accuracy: 0.8738\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.4274 - accuracy: 0.8737\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 1s 906us/step - loss: 0.4266 - accuracy: 0.8756\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 1s 916us/step - loss: 0.4282 - accuracy: 0.8751\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.4253 - accuracy: 0.8761\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 1s 879us/step - loss: 0.4269 - accuracy: 0.8734\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.4283 - accuracy: 0.8752\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 1s 911us/step - loss: 0.4270 - accuracy: 0.8742\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 1s 903us/step - loss: 0.4267 - accuracy: 0.8749\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 0.4281 - accuracy: 0.8746\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 1s 914us/step - loss: 0.4267 - accuracy: 0.8760\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 0.4284 - accuracy: 0.8747\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 0.4279 - accuracy: 0.8749\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 1s 951us/step - loss: 0.4261 - accuracy: 0.8754\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 1s 931us/step - loss: 0.4271 - accuracy: 0.8746\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 1s 930us/step - loss: 0.4262 - accuracy: 0.8756\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4277 - accuracy: 0.8748\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.4269 - accuracy: 0.8753\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 0.4290 - accuracy: 0.8749\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4268 - accuracy: 0.8746\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 0.4279 - accuracy: 0.8742\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 0.4282 - accuracy: 0.8740\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 0.4284 - accuracy: 0.8742\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 0.4287 - accuracy: 0.8740\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 0.4277 - accuracy: 0.8747\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.4284 - accuracy: 0.8743\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.4262 - accuracy: 0.8753\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 1s 872us/step - loss: 0.4270 - accuracy: 0.8748\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4270 - accuracy: 0.8754\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.4260 - accuracy: 0.8749\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.4273 - accuracy: 0.8747\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 0.4272 - accuracy: 0.8740\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 1s 908us/step - loss: 0.4272 - accuracy: 0.8751\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 0.4261 - accuracy: 0.8733\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 0.4277 - accuracy: 0.8752\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 0.4270 - accuracy: 0.8748\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 0.4275 - accuracy: 0.8740\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.4267 - accuracy: 0.8745\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.4269 - accuracy: 0.8742\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.4275 - accuracy: 0.8740\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.4287 - accuracy: 0.8753\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 0.4283 - accuracy: 0.8745\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.4269 - accuracy: 0.8750\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4273 - accuracy: 0.8754\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 0.4271 - accuracy: 0.8733\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4285 - accuracy: 0.8748\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.4286 - accuracy: 0.8747\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4275 - accuracy: 0.8748\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.4287 - accuracy: 0.8754\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.4300 - accuracy: 0.8745\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.4297 - accuracy: 0.8733\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.4296 - accuracy: 0.8751\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 0.4270 - accuracy: 0.8747\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.4294 - accuracy: 0.8758\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.4288 - accuracy: 0.8747\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4294 - accuracy: 0.8745\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.4298 - accuracy: 0.8750\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 0.4278 - accuracy: 0.8747\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 0.4302 - accuracy: 0.8743\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.4294 - accuracy: 0.8746\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.4284 - accuracy: 0.8745\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.4297 - accuracy: 0.8745\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.4301 - accuracy: 0.8740\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 0.4279 - accuracy: 0.8743\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 0.4287 - accuracy: 0.8745\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.4295 - accuracy: 0.8746\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4286 - accuracy: 0.8749\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4292 - accuracy: 0.8745\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.4291 - accuracy: 0.8745\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.4285 - accuracy: 0.8748\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.4293 - accuracy: 0.8738\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.4282 - accuracy: 0.8743\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 0.4281 - accuracy: 0.8756\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.4290 - accuracy: 0.8740\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.4289 - accuracy: 0.8751\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 1s 724us/step - loss: 0.4295 - accuracy: 0.8734\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.4277 - accuracy: 0.8743\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.4279 - accuracy: 0.8741\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 0.4284 - accuracy: 0.8741\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.4282 - accuracy: 0.8750\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.4286 - accuracy: 0.8747\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 0.4289 - accuracy: 0.8748\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.4292 - accuracy: 0.8743\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 0.4299 - accuracy: 0.8747\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.4296 - accuracy: 0.8753\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.4311 - accuracy: 0.8738\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.4296 - accuracy: 0.8749\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.4296 - accuracy: 0.8748\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 0.4288 - accuracy: 0.8737\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.4293 - accuracy: 0.8753\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.4300 - accuracy: 0.8742\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.4307 - accuracy: 0.8737\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.4277 - accuracy: 0.8753\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.4285 - accuracy: 0.8744\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 0.4294 - accuracy: 0.8750\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.4294 - accuracy: 0.8749\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.4305 - accuracy: 0.8739\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.4277 - accuracy: 0.8751\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.4285 - accuracy: 0.8748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b00c156610>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "model.fit(train_scaled, train_target, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd089e8",
   "metadata": {},
   "source": [
    "#### 결론\n",
    "- 딥러닝 : 인공신경망, 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘\n",
    "    - 이미지, 음성, 텍스트, 영상 분야에 뛰어난 성능 발휘\n",
    "- 밀집층 : Dense Layer. 가장 간단한 인공신경망\n",
    "- 원-핫 인코딩 : 해당 요소만 1로 나머지는 0으로 변환하는 방식\n",
    "    - [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] - 티셔츠\n",
    "    - [0, 0, 0, 0, 0, 0, 1, 0, 0, 0] - 스니커즈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483aa96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
